project: USERNAME/googleai-object-detection

name: Google AI object detection
tags: [solution-1]

metric:
  channel: 'MAP'
  goal: maximize

#Comment out if not in Cloud Environment
#pip-requirements-file: requirements.txt

exclude:
  - .git
  - .idea
  - .ipynb_checkpoints
  - output
  - imgs
  - neptune.log
  - offline_job.log
  - notebooks
  - src/object_detection

parameters:
# Data Paths
  train_imgs_dir: /mnt/chicm/data/train/224
  test_imgs_dir: /mnt/chicm/data/test/224
  annotations_filepath: /mnt/chicm/data/annotations/challenge-2018-train-annotations-bbox.csv
  annotations_human_labels_filepath: /mnt/chicm/data/annotations/challenge-2018-train-annotations-human-imagelabels.csv
  bbox_hierarchy_filepath: /mnt/chicm/data/annotations/bbox_labels_500_hierarchy.json
  class_mappings_filepath: /mnt/chicm/data/annotations/challenge-2018-class-descriptions-500.csv
  valid_ids_filepath: /mnt/chicm/data/annotations/challenge-2018-image-ids-valset-od.csv
  sample_submission: /mnt/chicm/data/test/sample_submission.csv
  #experiment_dir:  /home/chicm/ml/kaggle/open-solution-googleai-object-detection/experiment
  experiment_dir: ./experiment
  clone_experiment_dir_from: '' #When running eval specify this as for example /input/GAI-14/output/experiment

  # Execution
  clean_experiment_directory_before_training: 0
  num_workers: 16
  num_threads: 4
  load_in_memory: 0
  pin_memory: 1
  default_valid_ids: 1
  loader_mode: resize
  stream_mode: 0
  validate_with_map: 1
  small_annotations_size: 20
  kaggle_message: 'solution-1'

  # General parameters
  sampler_name: 'fixed'     # from {'fixed', 'aspect ratio'}
  even_class_sampling: 1
  image_h: 224
  image_w: 224
  short_dim: 400
  long_dim: 600
  image_channels: 3
  pad_method: 'resize'
  #desired_class_subset: "['Poster', 'Cat', 'Train', 'Dog', 'Bus','Truck', 'Picture frame', 'Airplane', 'Sculpture', 'Motorcycle']"

  # Retina parameters (multi-output)
  encoder_depth: 50
  num_classes: 500
  pretrained_encoder: 1
  pi: 0.01
  aspect_ratios: '[1/2., 1/1., 2/1.]'
  scale_ratios: '[1., pow(2,1/3.), pow(2,2/3.)]'

  # Training schedule
  epochs_nr: 10
  batch_size_train: 256
  batch_size_inference: 1024
  lr: 0.0001
  momentum: 0.9
  gamma: 1.0
  patience: 30
  lr_factor: 0.3
  lr_patience: 30
  training_sample_size: 50000
  validation_sample_size: 500

  # Regularization
  use_batch_norm: 1
  l2_reg_conv: 0.0001
  l2_reg_dense: 0.0
  dropout_conv: 0.1
  dropout_dense: 0.0

  # Postprocessing
  classification_threshold: 0.05
  nms_threshold: 0.5
